{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Language Modeling (CLM) - Preprocess, Training and Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will explore **Causal Language Modeling (CLM)**, which is a core task in training autoregressive language models like GPT-2. CLM is the process of predicting the next word in a sequence, given the previous words. This type of modeling forms the backbone of text generation tasks, where the model learns to generate coherent text by focusing only on previous tokens in the sequence.\n",
    "\n",
    "The lab is divided into three major sections:\n",
    "1. **Preprocessing**: Preparing a dataset and the labels for the CLM task and tokenizing them.\n",
    "2. **Training**: Fine-tuning a pre-trained language model like GPT-2 on a specific dataset using the CLM task.\n",
    "3. **Inference**: Evaluating the modelâ€™s performance by generating text based on input prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Load the Domain-Specific Dataset**:\n",
    "   - The first step in fine-tuning GPT-2 is to load a dataset that is specific to the domain of interest. In this case, we are using a publicly available **medical dataset** from the **PubMed** collection. PubMed contains a vast number of medical articles, and fine-tuning on such a dataset can help GPT-2 generate more accurate and context-specific medical text.\n",
    "   - The dataset we're using is `\"japhba/pubmed_simple\"`, which is a simplified version of PubMed data. This dataset can be easily accessed using the `datasets` library from Hugging Face.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"japhba/pubmed_simple\", split=\"train\")\n",
    "train_dataset = ds.shuffle(seed=42).select(range(1000))\n",
    "eval_dataset = ds.shuffle(seed=42).select(range(1000, 1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['abstract', 'country'],\n",
       "    num_rows: 3116832\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the contents of any one of the examples in the dataset to understand the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract': 'Purpose The identification of abnormalities that are relatively rare within otherwise normal anatomy is a major challenge for deep learning in the semantic segmentation of medical images. The small number of samples of the minority classes in the training data makes the learning of optimal classification challenging, while the more frequently occurring samples of the majority class hamper the generalization of the classification boundary between infrequently occurring target objects and classes. In this paper, we developed a novel generative multi-adversarial network, called Ensemble-GAN, for mitigating this class imbalance problem in the semantic segmentation of abdominal images.Method The Ensemble-GAN framework is composed of a single-generator and a multi-discriminator variant for handling the class imbalance problem to provide a better generalization than existing approaches. The ensemble model aggregates the estimates of multiple models by training from different initializations and losses from various subsets of the training data. The single generator network analyzes the input image as a condition to predict a corresponding semantic segmentation image by use of feedback from the ensemble of discriminator networks. To evaluate the framework, we trained our framework on two public datasets, with different imbalance ratios and imaging modalities: the Chaos 2019 and the LiTS 2017.Result In terms of the F1 score, the accuracies of the semantic segmentation of healthy spleen, liver, and left and right kidneys were 0.93, 0.96, 0.90 and 0.94, respectively. The overall F1 scores for simultaneous segmentation of the lesions and liver were 0.83 and 0.94, respectively.Conclusion The proposed Ensemble-GAN framework demonstrated outstanding performance in the semantic segmentation of medical images in comparison with other approaches on popular abdominal imaging benchmarks. The Ensemble-GAN has the potential to segment abdominal images more accurately than human experts.',\n",
       " 'country': 'US'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the each entry is a dictionary with two keys:\n",
    "- \"abstract\": The abstract of the medical article\n",
    "- \"country\": The country where the article was published (we will not use this information in this lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Tokenize the Dataset**:\n",
    "   - The next step is to **tokenize** the data so that it can be processed by GPT-2.\n",
    "   - GPT-2 does not natively use a padding token, since it does not require fixed length inputs. For this reason, we will substite it with the EOS token as suggested by transformers library (remember, we are also passing an attention mask, so whatever value is used for padding will be ignored by the model!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the Dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set padding token to EOS token\n",
    "\n",
    "def tokenize_function(samples):\n",
    "    return tokenizer(samples['abstract'], truncation=True, padding=\"max_length\")\n",
    "\n",
    "tokenized_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset_eval = eval_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Add labels to the Dataset for Next Token Prediction**:\n",
    "   - In this step, we will add the **labels** that will be used during the next token prediction task. \n",
    "   - In autoregressive language modeling, the **labels** represent the same sequence as the input, shifted one token to the right. This is because the model is trained to predict the next token in the sequence given the previous tokens.\n",
    "   - The shifting of the tokens is already handled automatically by the `Trainer` class. We just pass an extra attribute named `labels` to the dataset (when this argument is passed to the model, it will know to compute the loss for us!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels to the dataset\n",
    "def add_labels(samples):\n",
    "    samples[\"labels\"] = samples[\"input_ids\"]\n",
    "    return samples\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.map(add_labels, batched=True)\n",
    "tokenized_dataset_eval = tokenized_dataset_eval.map(add_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['abstract', 'country', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30026,\n",
       " 3455,\n",
       " 383,\n",
       " 11795,\n",
       " 286,\n",
       " 34615,\n",
       " 326,\n",
       " 389,\n",
       " 5365,\n",
       " 4071,\n",
       " 1626,\n",
       " 4306,\n",
       " 3487,\n",
       " 33449,\n",
       " 318,\n",
       " 257,\n",
       " 1688,\n",
       " 4427,\n",
       " 329,\n",
       " 2769,\n",
       " 4673,\n",
       " 287,\n",
       " 262,\n",
       " 37865,\n",
       " 10618,\n",
       " 341,\n",
       " 286,\n",
       " 3315,\n",
       " 4263,\n",
       " 13,\n",
       " 383,\n",
       " 1402,\n",
       " 1271,\n",
       " 286,\n",
       " 8405,\n",
       " 286,\n",
       " 262,\n",
       " 9137,\n",
       " 6097,\n",
       " 287,\n",
       " 262,\n",
       " 3047,\n",
       " 1366,\n",
       " 1838,\n",
       " 262,\n",
       " 4673,\n",
       " 286,\n",
       " 16586,\n",
       " 17923,\n",
       " 9389,\n",
       " 11,\n",
       " 981,\n",
       " 262,\n",
       " 517,\n",
       " 6777,\n",
       " 14963,\n",
       " 8405,\n",
       " 286,\n",
       " 262,\n",
       " 3741,\n",
       " 1398,\n",
       " 8891,\n",
       " 525,\n",
       " 262,\n",
       " 2276,\n",
       " 1634,\n",
       " 286,\n",
       " 262,\n",
       " 17923,\n",
       " 18645,\n",
       " 1022,\n",
       " 1167,\n",
       " 37971,\n",
       " 14963,\n",
       " 2496,\n",
       " 5563,\n",
       " 290,\n",
       " 6097,\n",
       " 13,\n",
       " 554,\n",
       " 428,\n",
       " 3348,\n",
       " 11,\n",
       " 356,\n",
       " 4166,\n",
       " 257,\n",
       " 5337,\n",
       " 1152,\n",
       " 876,\n",
       " 5021,\n",
       " 12,\n",
       " 324,\n",
       " 690,\n",
       " 36098,\n",
       " 3127,\n",
       " 11,\n",
       " 1444,\n",
       " 2039,\n",
       " 15140,\n",
       " 12,\n",
       " 45028,\n",
       " 11,\n",
       " 329,\n",
       " 47165,\n",
       " 428,\n",
       " 1398,\n",
       " 32556,\n",
       " 1917,\n",
       " 287,\n",
       " 262,\n",
       " 37865,\n",
       " 10618,\n",
       " 341,\n",
       " 286,\n",
       " 32692,\n",
       " 4263,\n",
       " 13,\n",
       " 17410,\n",
       " 383,\n",
       " 2039,\n",
       " 15140,\n",
       " 12,\n",
       " 45028,\n",
       " 9355,\n",
       " 318,\n",
       " 13160,\n",
       " 286,\n",
       " 257,\n",
       " 2060,\n",
       " 12,\n",
       " 8612,\n",
       " 1352,\n",
       " 290,\n",
       " 257,\n",
       " 5021,\n",
       " 12,\n",
       " 15410,\n",
       " 3036,\n",
       " 20900,\n",
       " 15304,\n",
       " 329,\n",
       " 9041,\n",
       " 262,\n",
       " 1398,\n",
       " 32556,\n",
       " 1917,\n",
       " 284,\n",
       " 2148,\n",
       " 257,\n",
       " 1365,\n",
       " 2276,\n",
       " 1634,\n",
       " 621,\n",
       " 4683,\n",
       " 10581,\n",
       " 13,\n",
       " 383,\n",
       " 34549,\n",
       " 2746,\n",
       " 13262,\n",
       " 689,\n",
       " 262,\n",
       " 7746,\n",
       " 286,\n",
       " 3294,\n",
       " 4981,\n",
       " 416,\n",
       " 3047,\n",
       " 422,\n",
       " 1180,\n",
       " 4238,\n",
       " 4582,\n",
       " 290,\n",
       " 9089,\n",
       " 422,\n",
       " 2972,\n",
       " 6352,\n",
       " 1039,\n",
       " 286,\n",
       " 262,\n",
       " 3047,\n",
       " 1366,\n",
       " 13,\n",
       " 383,\n",
       " 2060,\n",
       " 17301,\n",
       " 3127,\n",
       " 4284,\n",
       " 12271,\n",
       " 262,\n",
       " 5128,\n",
       " 2939,\n",
       " 355,\n",
       " 257,\n",
       " 4006,\n",
       " 284,\n",
       " 4331,\n",
       " 257,\n",
       " 11188,\n",
       " 37865,\n",
       " 10618,\n",
       " 341,\n",
       " 2939,\n",
       " 416,\n",
       " 779,\n",
       " 286,\n",
       " 7538,\n",
       " 422,\n",
       " 262,\n",
       " 34549,\n",
       " 286,\n",
       " 6534,\n",
       " 20900,\n",
       " 7686,\n",
       " 13,\n",
       " 1675,\n",
       " 13446,\n",
       " 262,\n",
       " 9355,\n",
       " 11,\n",
       " 356,\n",
       " 8776,\n",
       " 674,\n",
       " 9355,\n",
       " 319,\n",
       " 734,\n",
       " 1171,\n",
       " 40522,\n",
       " 11,\n",
       " 351,\n",
       " 1180,\n",
       " 32556,\n",
       " 22423,\n",
       " 290,\n",
       " 19560,\n",
       " 953,\n",
       " 27969,\n",
       " 25,\n",
       " 262,\n",
       " 13903,\n",
       " 13130,\n",
       " 290,\n",
       " 262,\n",
       " 7455,\n",
       " 4694,\n",
       " 2177,\n",
       " 13,\n",
       " 23004,\n",
       " 554,\n",
       " 2846,\n",
       " 286,\n",
       " 262,\n",
       " 376,\n",
       " 16,\n",
       " 4776,\n",
       " 11,\n",
       " 262,\n",
       " 4431,\n",
       " 13433,\n",
       " 286,\n",
       " 262,\n",
       " 37865,\n",
       " 10618,\n",
       " 341,\n",
       " 286,\n",
       " 5448,\n",
       " 599,\n",
       " 20042,\n",
       " 11,\n",
       " 14383,\n",
       " 11,\n",
       " 290,\n",
       " 1364,\n",
       " 290,\n",
       " 826,\n",
       " 41395,\n",
       " 547,\n",
       " 657,\n",
       " 13,\n",
       " 6052,\n",
       " 11,\n",
       " 657,\n",
       " 13,\n",
       " 4846,\n",
       " 11,\n",
       " 657,\n",
       " 13,\n",
       " 3829,\n",
       " 290,\n",
       " 657,\n",
       " 13,\n",
       " 5824,\n",
       " 11,\n",
       " 8148,\n",
       " 13,\n",
       " 383,\n",
       " 4045,\n",
       " 376,\n",
       " 16,\n",
       " 8198,\n",
       " 329,\n",
       " 29526,\n",
       " 10618,\n",
       " 341,\n",
       " 286,\n",
       " 262,\n",
       " 35258,\n",
       " 290,\n",
       " 14383,\n",
       " 547,\n",
       " 657,\n",
       " 13,\n",
       " 5999,\n",
       " 290,\n",
       " 657,\n",
       " 13,\n",
       " 5824,\n",
       " 11,\n",
       " 8148,\n",
       " 13,\n",
       " 21481,\n",
       " 383,\n",
       " 5150,\n",
       " 2039,\n",
       " 15140,\n",
       " 12,\n",
       " 45028,\n",
       " 9355,\n",
       " 9555,\n",
       " 11660,\n",
       " 2854,\n",
       " 287,\n",
       " 262,\n",
       " 37865,\n",
       " 10618,\n",
       " 341,\n",
       " 286,\n",
       " 3315,\n",
       " 4263,\n",
       " 287,\n",
       " 7208,\n",
       " 351,\n",
       " 584,\n",
       " 10581,\n",
       " 319,\n",
       " 2968,\n",
       " 32692,\n",
       " 19560,\n",
       " 31747,\n",
       " 13,\n",
       " 383,\n",
       " 2039,\n",
       " 15140,\n",
       " 12,\n",
       " 45028,\n",
       " 468,\n",
       " 262,\n",
       " 2785,\n",
       " 284,\n",
       " 10618,\n",
       " 32692,\n",
       " 4263,\n",
       " 517,\n",
       " 14351,\n",
       " 621,\n",
       " 1692,\n",
       " 6154,\n",
       " 13,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " 50256,\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[0]['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Fine-Tune the GPT-2 Model**:\n",
    "   - Set up the model and finetune it using the medical dataset. \n",
    "   - The pipeline to be followed is the same that we have already seen in the previous lab (`lab03 - 01-bert`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csavelli/llm/.conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [84/84 03:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.733921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.726320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.722076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.721293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.718880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.718112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.717467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.716999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set Training Parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-medical-finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=6,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    eval_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    ")\n",
    "\n",
    "# Initialize GPT-2 Model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "import transformers\n",
    "# Fine-Tune the Model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset_eval,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save the Fine-Tuned Model\n",
    "model.save_pretrained(\"./gpt2-medical-finetuned\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Compare Text Generation Before and After Fine-Tuning**:\n",
    "   - Generate text using both the original pre-trained GPT-2 model and the fine-tuned model.\n",
    "   - Provide the same input prompt and observe the differences in the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the pre-trained and fine-tuned GPT-2 models\n",
    "pretrained_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(\"./gpt2-medical-finetuned\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "prompt = \"The patient presents with chest pain and shortness of breath.\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "input_ids = inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Before Fine-Tuning (Pre-Trained GPT-2)**:\n",
      "The patient presents with chest pain and shortness of breath. At 6 weeks, there was no evidence of an underlying vascular problem.\n",
      "\n",
      "In the end, this patient showed only moderate to severe brain damage while an MRI of the patient revealed that there was no neurological impact. The patient had a partial brain bleed in the spinal cord, but no other signs of injury.\n",
      "\n",
      "The clinical outcome of the MRI included: decreased head height of at least 10 cm with a mean brain length of 10 cm\n"
     ]
    }
   ],
   "source": [
    "# Generate Output of the Model Before Fine-Tuning\n",
    "output_pretrained = pretrained_model.generate(input_ids, do_sample=True, max_length=100, temperature=1.0, pad_token_id=tokenizer.eos_token_id) # (assigning pad_token_id avoids a warning)\n",
    "generated_pretrained = tokenizer.decode(output_pretrained[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"**Before Fine-Tuning (Pre-Trained GPT-2)**:\")\n",
    "print(generated_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**After Fine-Tuning (Fine-Tuned on Medical Dataset)**:\n",
      "The patient presents with chest pain and shortness of breath. The patient has a single and small hemorrhagic thrombotic episode in the second episode of respiratory depression. The following symptoms were reported to the patient.\n"
     ]
    }
   ],
   "source": [
    "# Generate Output of the Model After Fine-Tuning\n",
    "output_finetuned = finetuned_model.generate(input_ids, do_sample=True, max_length=100, temperature=1.0, pad_token_id=tokenizer.eos_token_id) # (assigning pad_token_id avoids a warning)\n",
    "generated_finetuned = tokenizer.decode(output_finetuned[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"**After Fine-Tuning (Fine-Tuned on Medical Dataset)**:\")\n",
    "print(generated_finetuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Extra stuff!</span>\n",
    "\n",
    "Training the model in this way produces batches with potentially very different lengths. This can be inefficient, as the model will have to pad the sequences to the length of the longest sequence in the batch.\n",
    "\n",
    "To avoid this, we can use a technique called **Dynamic Padding**. This technique groups the sequences in the batch by length and pads them to the length of the longest sequence in each group. This way, the model only has to pad the sequences to the length of the longest sequence in each group, which can significantly reduce the amount of padding required.\n",
    "\n",
    "As a first exercise, quantify the number of pad tokens being used in various situations:\n",
    "1. You pad all batches to the maximum allowed sequence length (1024 for GPT-2, this is what we used so far)\n",
    "2. You pad the entire batch to the length of the longest sequence in the batch (generate the batches by randomly sampling sentences)\n",
    "3. You pad the entire batch to the length of the longest sequence in the batch (generate the batches by placing sentences of similar lengths together)\n",
    "\n",
    "Next, introduce dynamic padding and compare the execution times of the previous execution and the one with dynamic padding.\n",
    "\n",
    "You can use the following resources to help you with this exercise:\n",
    "- `group_by_length` parameter ([TrainingArguments](https://huggingface.co/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.TrainingArguments.group_by_length)) (parameter to group together samples with similar lengths)\n",
    "- `DataCollatorForSeq2Seq` ([DataCollatorForSeq2Seq](https://huggingface.co/docs/transformers/main_classes/data_collator#transformers.DataCollatorForSeq2Seq)) (collator function that aggregates samples into batches and pads them to the maximum length of the batch)\n",
    "\n",
    "Note: you may find that the validation losses you observe may be different from the previous ones. This is because the cross entropy loss is computed as an average across tokens, and the number of tokens in a batch can vary depending on the padding strategy used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
